# SAC Configuration for Box2D Environments

# LunarLander-v3 configuration
LunarLander-v3:
  episodes: 2000

  discount_factor: 0.99
  tau: 0.005

  learning_rate_actor: 0.0003
  learning_rate_critic: 0.0007 # critics learn faster â†’ more stable
  batch_size: 256
  replay_memory_size: 200000

  automatic_entropy_tuning: true
  alpha: 0.2
  target_entropy: -2.0 # suitable for 2-dim continuous actions

  start_steps: 10000 # collect samples before learning
  update_after: 5000
  updates_per_step: 1

  gradient_clip: 1.0
  reward_scale: 1.0

  # Early stop training if solved
  convergence_threshold: 180 # stop when average > 180
  convergence_window: 100

# CarRacing-v3 configuration
CarRacing-v3:
  episodes: 1500
  learning_rate: 0.0003
  discount_factor: 0.99
  tau: 0.005
  alpha: 0.2
  automatic_entropy_tuning: true
  batch_size: 256
  replay_memory_size: 500000
  warmup_steps: 5000
  max_episode_steps: 1000
